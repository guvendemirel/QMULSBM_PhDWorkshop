{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a98acf",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/guvendemirel/QMULSBM_PhDWorkshop/blob/master/SBM_PhD_python_ws_part3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1582f9",
   "metadata": {},
   "source": [
    "# QMUL SBM PHD Python Workshop - Part 3\n",
    "\n",
    "In this session, we will continue with functions and Numpy and Pandas packages for numerical operations and working with tabular data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37841b",
   "metadata": {},
   "source": [
    "## Functions\n",
    "Functions are crucial building blocks of programming, which eliminate redundancy and provide abstraction. If you repeat a certain code that solves a non-trivial task in different parts of your code, it is a good indication that you should introduce a function. Organizing your blocks of code into functions provides an abstraction, which makes it easier to understand your code. Furthermore, the maintenance of code is easier with functions. We have so far used several built-in functions, e.g. `print` function, or functions from other packages such as Numpy, e.g. `np.sqrt()`. The functions are called by providing their arguments, lists of which can be checked from the help.\n",
    "\n",
    "We can also define our own functions. Let's now define a simple function. **Positional arguments** must always be provided inputs. Default values are used for **keyword arguments** if no value is provided. The function definition syntax is as follows:\n",
    "\n",
    "```python\n",
    "def function_name(arg1, arg2 = val2):\n",
    "    code\n",
    "    return value\n",
    "```\n",
    "\n",
    "### Namespaces\n",
    "The local namespace (variable scope) is created when the function is called and the arguments are automatically loaded. You can also use variables from the global namespace in the local namespace. However, you cannot change their values. If you try, a new variable is created. You must use the `global` keyword if you want to update its value.\n",
    "\n",
    "As an example, let's write a function that cleans the names of subject areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b540d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expressions library for handling text\n",
    "\n",
    "courses = [' accounting ', 'finance ', 'Marketing ', 'supply chain management#', '?interna92tional BuSiness1\\n']\n",
    "\n",
    "# Create a list of characters to remove\n",
    "remove_chars = '[_!#?*0-9]'\n",
    "\n",
    "def clean_name(name):\n",
    "    cl_name = __.strip() #remove the beginning and ending white spaces and new lines\n",
    "    cl_name = re.sub(remove_chars, '', __) #remove irrelevant characters\n",
    "    cl_name = __.title() #first letter capital \n",
    "    __\n",
    "\n",
    "# Write a list comprehension that applies clean_name to each name in the courses list\n",
    "cleaned_courses = __\n",
    "cleaned_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800a616",
   "metadata": {},
   "source": [
    "Final check about variable scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if you try accessing cl_name outside the function (in the global scope), \n",
    "# where it is not in the namespace?\n",
    "cl_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea728af0",
   "metadata": {},
   "source": [
    "Since in Python everything is an object, the variables are passed by object (reference), in contrast to passing by value, which is common in most other languages. The behaviour depends on whether the argument is of mutable vs immutable data type, similar to the behaviour of variable assignment as we have seen before. The following exercises illustrate variable scopes and the behaviour for mutable and immutable arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the following code - Version 1\n",
    "def clean_name(name):\n",
    "    name = name.strip() \n",
    "    name = re.sub(remove_chars, '', name) \n",
    "    name = name.title()\n",
    "    return name\n",
    "\n",
    "name1 = \"?businesS analytics#\"\n",
    "name2 = clean_name(__)\n",
    "\n",
    "# What output do you expect and why?\n",
    "print(name1, name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the following code - Version 2\n",
    "def clean_name_alt(name):\n",
    "    name1 = name.strip() \n",
    "    name1 = re.sub(remove_chars, '', name1) \n",
    "    name1 = name1.title() #first letter capital \n",
    "    return name1\n",
    "\n",
    "name1 = \"something else\"\n",
    "name2 = \"?businesS analytics#\"\n",
    "name3 = clean_name_alt(name2)\n",
    "\n",
    "# What output do you expect and why?\n",
    "print(name1, name2, name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad409d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the following code - Version 3\n",
    "def clean_name_alt(name):\n",
    "    # set the scope of the variable to global\n",
    "    __ \n",
    "    name1 = name.strip() \n",
    "    name1 = re.sub(remove_chars, '', name1) \n",
    "    name1 = name1.title() #first letter capital \n",
    "    return __\n",
    "\n",
    "name1 = \"something else\"\n",
    "name2 = \"?businesS analytics#\"\n",
    "name3 = clean_name_alt(name2)\n",
    "\n",
    "# What output do you expect and why?\n",
    "print(name1, name2, name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether name1 and name3 are the same object\n",
    "__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with list arguments\n",
    "\n",
    "# Global scope:\n",
    "courses = [' accounting ', 'finance ', 'Marketing ', 'supply chain management#', '?interna92tional BuSiness1\\n']\n",
    "no_courses = 0\n",
    "\n",
    "def clean_names(name_list):\n",
    "    # set the scope to global\n",
    "    __ no_courses\n",
    "    # loop over the list by both index and value\n",
    "    for __, __ in __:\n",
    "        # increment no_courses\n",
    "        __\n",
    "        # call clean_name function and update the list\n",
    "        __        \n",
    "\n",
    "# clean the courses list\n",
    "__\n",
    "\n",
    "# What output do you expect and why?\n",
    "print(courses, no_courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0db24",
   "metadata": {},
   "source": [
    "## Numpy Package\n",
    "NumPy is the main package for numerical computations in Python. It is used together with the Pandas package for data analysis. Numpy is highly efficient even for large amounts of data because its methods are implemented in C. NumPy provides methods, operations, and functions that can be applied to whole arrays without the need for loops or list comprehensions.\n",
    "\n",
    "### Numpy Arrays\n",
    "The core data structure of Numpy is `ndarray` (N-dimensional array). Arrays are homogeneous, meaning that all units have the same data type (mostly numeric and logical), differently from lists that are heterogeneous. With arrays, you can apply operations as if they were scalars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy package\n",
    "__\n",
    "\n",
    "# Set the seed for random numbers\n",
    "__\n",
    "\n",
    "# Create my_array 2 x 3 array of standard normal variables\n",
    "my_array = __.__.__((2, 3)) \n",
    "my_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ee8a0",
   "metadata": {},
   "source": [
    "All mathematical operators are applied element-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply all entries of my_array by 10\n",
    "10 * my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 0.2*my_array from my_array\n",
    "__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b97ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide 10 by each entry of my_array\n",
    "__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise 0.2 to the power given by each entry of my_array\n",
    "__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the fourth power of each entry of my_array\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4494f5",
   "metadata": {},
   "source": [
    "You can access the shape of the array by the `shape` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns does my array have my_array?\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf45af",
   "metadata": {},
   "source": [
    "You can create arrays from other collections by using the `np.array()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ba649",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [3, 6, -2]\n",
    "# Create my_array from my_list\n",
    "my_array = __\n",
    "# Change the values of both my_list and my_array\n",
    "my_list *= 4  \n",
    "my_array *= 2\n",
    "\n",
    "# What results do you expect?\n",
    "print(my_list, my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c352ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [3, 6, -2]\n",
    "# create a list that contains 2 * each value of my_list elements\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5863cc",
   "metadata": {},
   "source": [
    "You can create two-dimensional arrays from lists with equal length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7387be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n",
    "# Create 2D array from data1\n",
    "arr1 = __\n",
    "# print arr1\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cca54d",
   "metadata": {},
   "source": [
    "A commonly used Numpy array method is `reshape((n1,n2))` which reshapes the array to a 2D array with n1 rows and n2 columns (can be applied to higher dimensional arrays). Another useful method is `ravel()`, which flattens the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(1, 13) -> 1, 2, 3, ..., 12\n",
    "# Numpy's arange is similar to the range iterator but returns an array \n",
    "arr2 = __\n",
    "# Print the array\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2349ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the array to 3x4 two-dimensional array\n",
    "arr2.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ac49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the array to 2 rows and assign to arr3\n",
    "arr3 = __\n",
    "\n",
    "# Flatten arr3\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25177fe",
   "metadata": {},
   "source": [
    "You can compare two numerical arrays to form a Boolean array.\n",
    "\n",
    "Create two standard normally distributed 2d (2x4) arrays and check whether the entry in the first array is greater than or equal to the second array entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = __\n",
    "arr2 = __\n",
    "# create the boolean array that contains whether arr1 value is greater than or equal to arr2 value\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068db94",
   "metadata": {},
   "source": [
    "## Indexing and Slicing Numpy Arrays\n",
    "Indexing and slicing are done in a very similar way to lists and tuples. If the array is high dimensional (at least 2), you provide indices for all dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([3, 6, -2, 7, 9])\n",
    "# The element in index 1\n",
    "print(__)\n",
    "# Slice that starts with the index 2 up until the end\n",
    "print(__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3750497",
   "metadata": {},
   "source": [
    "With Numpy arrays, you can pass multiple indices as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscript elements at index 0, 2, and 3\n",
    "arr1[__]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad43167",
   "metadata": {},
   "source": [
    "Working with 2D arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9bb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.arange(12).reshape(4,3)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d22eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscript to the element in row 1 and column 2\n",
    "__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice to the sub-matrix from row 2 to the last row and columns 0 and 2 (not 1)\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1c652",
   "metadata": {},
   "source": [
    "You can then assign values to these slices. If you assign a scalar, its value is repeated for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the dice above, assign the values to 100\n",
    "__\n",
    "# Print arr2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd2840",
   "metadata": {},
   "source": [
    "You can also index by using logical conditions, which you can equally apply to other collections such as lists and tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334cbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type conversion needed for the next replacement (remember homogeneous types)\n",
    "arr2 = arr2.astype(np.float64)\n",
    "\n",
    "# Identify the elements of arr2 which are greater than or equal to 7\n",
    "__\n",
    "\n",
    "# Set the values >= 7 to normal random numbers with mean 10, std dev =2\n",
    "arr2[__] = __(10, 2, np.sum(arr2 >= 7))\n",
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86224373",
   "metadata": {},
   "source": [
    "## Numpy functions\n",
    "Numpy provides a wide range of functions and methods that can be applied efficiently on arrays.  \n",
    "\n",
    "**Unary functions**:\n",
    "They are all element-wise transformations.\n",
    "- `abs`: Compute the absolute value\n",
    "- `sqrt`: Compute the square root\n",
    "- `exp`: Compute the exponential\n",
    "- `log`,`log10`: Natural logarithm, log base 10\n",
    "- `sign`: Compute the sign\n",
    "- `rint`: Round to the nearest integer\n",
    "- `isnan`: Return boolean array indicating whether each value is NaN (Not a Number)\n",
    "- `cos`, `cosh`, `sin`, `sinh`, `tan`, `tanh`: Regular and hyperbolic trigonometric functions\n",
    "\n",
    "**Binary functions:**\n",
    "They take two arrays and return a single array as the result. \n",
    "- `maximum`: Element-wise maximum\n",
    "- `minimum`: Element-wise minimum\n",
    "- `mod`: Element-wise modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of 0, 1, ...,9\n",
    "arr1 = __\n",
    "# Exponentiate that array elementwise\n",
    "print(__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bfaf08",
   "metadata": {},
   "source": [
    "Create two standard normal 2d (2x4) arrays and choose the maximum of the two arrays for each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = __\n",
    "arr2 = __\n",
    "# Create arr3, which is elemtwise maximum of the two\n",
    "arr3 = __\n",
    "# Print arr1, arr2, arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378be3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(12).reshape(4,3)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall mean, sum, standard deviation\n",
    "arr.__, arr.__, arr.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c43f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean across the rows\n",
    "arr.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum across the columns\n",
    "arr.__  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9faa87c",
   "metadata": {},
   "source": [
    "## Working with Tabular Data: Pandas\n",
    "We will now learn the basics of Pandas, the Python package for working with tabular data, and start working on data pre-processing.\n",
    "\n",
    "Consider that you have just started working as an analyst at a film production company and your job involves analysing the market trends in the filming industry. As a data source on individual firms and audience preferences, you start your analysis by downloading the datasets on IMDB https://www.imdb.com/interfaces/. Your first objective is to clean data in the individual datasets and form an integrated dataset of movies produced in the past two decades, involving Title, Genre, Year, Runtime (Minutes), IMDB Rating, and Number of Votes data by merging two datasets.\n",
    "\n",
    "## Organising your workspace\n",
    "\n",
    "To work with data files, we must first ensure that they are in our working directory. In the below, we change the path to the directory in which we have the data files in our local drive. For this, we can use the shell commands by importing the `os` package. The function `os.getcwd()` returns the current working directory, while `os.chdir()` changes the working directory. The `os.path` module contains functions to work with path names in a way that is robust across operating systems (Windows, MacOS, and Linux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import os\n",
    "\n",
    "# Print your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# assign your home address to the variable HOME. The expanduser function is used to replace ~ with the home\n",
    "HOME = os.path.expanduser('~')\n",
    "\n",
    "# Locate the folder in which you saved the data and create a path by joining them\n",
    "# In my case, my HOME is \"C:\\Users\\Guven\" and my files are under \n",
    "# C:\\Users\\Guven\\Documents\\PhD workshop\\\n",
    "PROJECT_DIR = os.path.join(HOME, 'Documents', 'PhD workshop')\n",
    "\n",
    "# Change to the folder in which the dataset\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# Print your current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1106a",
   "metadata": {},
   "source": [
    "If you are working on Google Colab, do the following after you copy the files in the designated folder on your Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7aba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), 'drive', 'My Drive', 'Colab Notebooks'))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6d028",
   "metadata": {},
   "source": [
    "## Reading data with Pandas\n",
    "\n",
    "The first step of data analysis is reading data from files. Pandas library provides several functions for reading data from different types of files, including comma or tab separated files. We first read the data from the `title.basics.tsv.gz` file, which includes the following data fields:  \n",
    "- tconst (string) - alphanumeric unique identifier of the title\n",
    "- titleType (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
    "- primaryTitle (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
    "- originalTitle (string) - original title, in the original language\n",
    "- startYear (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
    "- endYear (YYYY) – TV Series end year. ‘\\N’ for all other title types\n",
    "- runtimeMinutes – primary runtime of the title, in minutes\n",
    "- genres (string array) – includes up to three genres associated with the title.\n",
    "\n",
    "We now read the data by the Pandas `read_csv` function, which takes the file path and `sep` (separator, which is `\\t` for tab in our data that is tab-seperated). This returns a `dataframe` object which includes different observations (films) in the rows, and features in the columns. Each row is identifed by its index value very much like Python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99929e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library (convention: as pd)\n",
    "__\n",
    "\n",
    "# Read the data from title_basics into the dataframe movies_df\n",
    "__ = __(__, sep=__, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd090c7b",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "We shall now explore the data set. For this, we can use the `head()` and `tail()` methods of the dataframe, which display the top or bottom rows, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 rows of movies_df\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f92f46",
   "metadata": {},
   "source": [
    "The column `tconst` is the unique identifier for the record. Hence, we would like to set it as the index by the `set_index()` method. The default behaviour of Pandas objects is not to mutate the original data frame and to return a new dataframe. To overwrite the orginal dataframe, you should pass the argument `inplace=True`. Passing the argument `drop=True` leads to dropping the column used for setting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.__(__, drop=__, __)\n",
    "\n",
    "# print the tail (last 5)\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77e4bb",
   "metadata": {},
   "source": [
    "The `info` method provides key information on the data frame, including names and types of variables, data shape (number of rows and columns), and memory. As you can see below, there are 8333396 titles recorded on IMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4046e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show info about the dataframe\n",
    "movies_df.__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3323340",
   "metadata": {},
   "source": [
    "We can now move to data cleaning. First, let's remove duplicate entries, if any, by the `drop_duplicates` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the initial number of rows?\n",
    "# Hint: you can use the shape attribute as in Numpy arrays\n",
    "N1 = movies_df.__\n",
    "\n",
    "# Drop the duplicates in-place\n",
    "__\n",
    "\n",
    "# Print the number of rows that have been dropped\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb93d995",
   "metadata": {},
   "source": [
    "We can obtain a view of one of the columns by using square brackets [], which keeps the association with the index and returns a Series. Since it is only a view of a part of the original dataframe, if we make any changes, it applies to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d780ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a view of the \"titleType\" series\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5933b8",
   "metadata": {},
   "source": [
    "Not all of the columns are relevant. Especially if you are working with big data sets, it is beneficial to drop the irrelevant variables directly. You need to identify these variables based on your research questions and initial exploration of the data set. You can use the `drop` method with the argument `axis = 1` to drop the columns, for which you pass the names. You can obtain the columns by using the `columns` attribute of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f904e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns [\"originalTitle\", \"isAdult\", \"endYear\"] \n",
    "__\n",
    "\n",
    "# Check the remaining columns by the columns attribute\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61df32",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "We need to treat string and numerical variables separately and handle the missing values properly. As an example, we shall first check how many numeric entries the `runtimeMinutes` has. For this, you can call the `pandas.Series.str` functions (`isnumeric` to check whether it is a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eadb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of entries \n",
    "print(__)\n",
    "    \n",
    "# Print the number of numeric entries of the runtimeMinutes column\n",
    "print(__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b035c",
   "metadata": {},
   "source": [
    "The missing values in this data set are encoded as `\\N`, which we replace with `None` to be properly handled by pandas. We use the `replace()` method to replace a given value with a desired value, in our case `\\\\N` with `None`. \n",
    "\n",
    "Note that all variables are currently held as `object` type, which is used when there is mixed datatype and for strings. As we will see, Pandas cannot infer the correct data types in this case due to missing values being recorded as string. We want to ultimately cast to the following data types:\n",
    "- 'titleType': 'string'\n",
    "- 'primaryTitle': 'string'\n",
    "- 'startYear': 'Int64'\n",
    "- 'runtimeMinutes': 'float64'\n",
    "- 'genres': 'string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing value place holder \\\\N with np.nan (missing value indicator)\n",
    "movies_df.__('\\\\N', __, __)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9dde75",
   "metadata": {},
   "source": [
    "We shall now check whether the numeric variables truely hold numeric entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070bd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of rows in the dataframe and the number of rows with numeric entries\n",
    "# for the 'startYear' column\n",
    "print(__, __, __)\n",
    "\n",
    "# for the 'runtimeMinutes' column\n",
    "print(__, __, __)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28403386",
   "metadata": {},
   "source": [
    "Since we see a mismatch in the 'runtimeMinutes, let's inspect the column and find the source of the problem. For this we will select the rows where the entry is not numeric passing a boolean array. If you have a dataframe `X` and you select the rows where the column `c1` satisfies a certain condition (say is negative) by `X[X['c1'] < 0]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the rows of the dataframe in which the `runTimeMinutes` is not numeric\n",
    "movies_df[__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-numeric runtimeMinutes with missing values\n",
    "movies_df.loc[__,__] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a709a51",
   "metadata": {},
   "source": [
    "We are now ready to correct the data types by using the method `astype()` to which we pass a dictionary of data types. Note that we cast 'startYear' as 'float64' first and then to 'Int64' because the 'object' type can be converted to float64 but not Int64 when there are missing values. A work-around is to first convert to float64 and then to int 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aec7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column dataypes\n",
    "column_types = {'titleType': 'string', 'primaryTitle': 'string', \n",
    "                'startYear': 'float32', 'runtimeMinutes': 'float32', \n",
    "                'genres': 'string'}\n",
    "\n",
    "# Convert all data types using the dictionary\n",
    "movies_df = movies_df.__(__) \n",
    "\n",
    "# Correct the data type for startYear\n",
    "movies_df['startYear'] = movies_df['startYear'].__('Int16')\n",
    "\n",
    "# Check the variables and data types\n",
    "movies_df.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a4b2e",
   "metadata": {},
   "source": [
    "We shall now inspect missing values. You can use the `isna()` method to obtain a data frame which holds a value `True` for cells where the data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fe545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many missing values there are for each variable\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f8ac8",
   "metadata": {},
   "source": [
    "We have only a handful of missing values in the Primary Title. We will exclude those without title.  For this, we use the `dropna()` method. You can specify when to drop, i.e. in which column when there is a missing value, by specifying the `subset` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows if they do not have a title\n",
    "movies_df.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef014d1",
   "metadata": {},
   "source": [
    " Let's drop cells if both `runtimeMinutes` and `genres` are missing. For this, you can use the `how='all'` argument of the `dropna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If both runtimeMinutes and genres are missing, drop that row\n",
    "movies_df.__(__=['runtimeMinutes', 'genres'], __, __)\n",
    "\n",
    "# Create a new data_frame by selecting only movies (titleType = 'movie') that were produced after 2000\n",
    "movies_selected_df = __"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b8916",
   "metadata": {},
   "source": [
    "We now drop the 'titleType' field, which is now always movie, hence not needed, rename the variables for convenience, and sort according to a given variable. The `rename()` method takes a dictionary as the columns arguments in the format {var1_old_name: var1_new_name, var2_old_name: var2_new_name}. We then sort the data in the ascending order of year by using the `sort_values()` method by setting the keyword argument `ascending=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column \"titleType\"\n",
    "movies_selected_df.__(__, axis = __, inplace = True)\n",
    "\n",
    "# Rename the variables\n",
    "movies_selected_df.__(columns = {'primaryTitle': 'movie', \n",
    "                            'startYear': 'year', \n",
    "                            'runtimeMinutes': 'minutes'}, \n",
    "                      inplace = True)\n",
    "\n",
    "# sort the dataframe wrt year in-place\n",
    "movies_selected_df.__ \n",
    "\n",
    "# show the head of the dataframe\n",
    "movies_selected_df.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678006c4",
   "metadata": {},
   "source": [
    "We can now impute the `minutes` by the median `minutes`. For this, we can use the `fillna()` method with the median as the positional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810048e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute any missing values in the minutes column by its median\n",
    "movies_selected_df['minutes'] = __\n",
    "\n",
    "# show the head of the dataframe\n",
    "movies_selected_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573b486",
   "metadata": {},
   "source": [
    "### DataFrame Merging\n",
    "We shall now merge the user ratings data with the movie dataframe. For this, we shall first read the title.ratings.tsv.gz dataset to a dataframe as we did for the first data set. Here, we will directly specify the index column, which is `tconst` as for the movie dataframe. This is done by passing the argument `index_col = 'tconst'`. We also set the data types by setting the `dtype` to corresponding data type.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset title_ratings.tsv to a dataframe and set the index and the data types\n",
    "ratings_df = __(\"title.ratings.tsv.gz\", __ = \"tconst\", \n",
    "                         __ = {'averageRating': 'float64', 'numVotes': 'Int64'}, \n",
    "                         sep = '\\t')\n",
    "\n",
    "#Show top rows\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac23f96",
   "metadata": {},
   "source": [
    "As you can see, it associates the same identifier `tconst` with the `averageRating` and `numVotes` variables.\n",
    "\n",
    "Pandas `merge` method allows merging a dataset with another dataset. Here, we use the index `tconst` for matching the two dataframes, by setting the arguments `left_index = True` and `right_index = True`. This means that if two rows in the two datasets have the same index value, they belong to the same entity (movie). The argument `how = 'inner'` specifies that all rows of the left and right frames should match. If there are non-matching indices in either, those rows are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner-Merge the ratings_df with movies_selected_df (key should exist in both)\n",
    "final_movies_df = movies_selected_df.__(__, how = __, left_index = __, right_index = __)\n",
    "\n",
    "# Show the head of the data frame\n",
    "final_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of entries\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b930e",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "We shall now look at the descriptive statistics for numeric variables by using the `describe` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ec8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check descriptive statistics\n",
    "final_movies_df.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c53cc",
   "metadata": {},
   "source": [
    "There seems to be some movies with very low number of votes. Hence, we shall slice only to those movies with at least 10000 votes. We shall then have a quick look at the top 10 movies with highest `averageRating`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only those movies with at least 10000 votes\n",
    "final_movies_df = __\n",
    "\n",
    "# Display the top 10 movies in terms of averageRating (if equal, more votes first)\n",
    "final_movies_df.__(__, ascending = __).__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8979752",
   "metadata": {},
   "source": [
    "We look at the correlation between numerical variables by using the `corr()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation coefficients \n",
    "final_movies_df.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5abb31",
   "metadata": {},
   "source": [
    "There are some positive correlations between the number of votes, average rating, and the minutes. However, the correlation coefficient is a linear measure of assocation and it does not mean causation. We shall look at scatterplots. \n",
    "\n",
    "Matplotlib is the main visualisation package in Python and standard plots are directly implemented as methods of dataframes. Hence, you can call the `plot` method directly from a dataframe object. Here, we specify the plot type by `kind = 'scatter'`. We provide the x and y axes and the title of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Scatter plot between numVotes and averageRating\n",
    "__.plot(kind = __, x =__, y = __, title =__, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36056360",
   "metadata": {},
   "source": [
    "We can see that the variation in averageRating decreases with numVotes, as expected since $SE(\\bar{x}) = \\frac{\\sigma}{\\sqrt{n}}$ if $n$ individual viewer ratings are independent (plausible) and randomly sampled. \n",
    "\n",
    "We shall now plot and inspect boxplots to see how ratings evolve over time. We can directly plot a boxplot using the `boxplot` method, specifying thecolumn for which to plot the boxplot. The optional argument `by = 'year'` specifies that we want to plot the boxplots separately for different values of the variable `year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot of averageRating by year\n",
    "final_movies_df.__(column = __, by = __, rot = 90, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cd4f44",
   "metadata": {},
   "source": [
    "The ratings look pretty stable over time.\n",
    "\n",
    "We shall finally look at the association between the genre and the movie rating. We must consider that each movie can belong to multiple genres. We first start by identifying the different genres. For this, we can use the `str` methods that we learned before. I copy some code below for this. Work on this on your own at home for practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c68cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cat method concatenates all entries in a column using the specified seperator (here ',')\n",
    "genres = final_movies_df[\"genres\"].str.cat(sep = ',') \n",
    "\n",
    "# This returns a long str of individual genres. To obtain a set of genres, we first\n",
    "# split from ',' to a list and then remove duplicates by the set() constructor\n",
    "genres = set(genres.split(','))\n",
    "\n",
    "# The following calculates the average of ratings for each genre in the list genres.\n",
    "# final_movies_df[\"genres\"].str.contains(genre) checks if each cell contains the genre being iterated\n",
    "# hence this will return a slice for the correct genre, for which we then extract\n",
    "# the \"averageRating\" column and take its mean\n",
    "avg_ratings = {genre: final_movies_df[final_movies_df[\"genres\"].str.contains(genre)][\"averageRating\"].mean() \n",
    "               for genre in genres}\n",
    "avg_ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
